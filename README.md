# Audio DeepFake Detection



## ğŸ” Project Overview

**Audio DeepFake Detection** is an intelligent system designed to classify audio files as **real** or **fake**.  
It uses **machine learning** techniques to analyze audio feature sets and predict authenticity, providing a simple and interactive **Streamlit**-based user interface for real-time testing.

This project primarily leverages:
- A **Random Forest Classifier** trained on extracted audio features (e.g., MFCCs, Spectral Centroid, Zero-Crossing Rate, etc.).
- A **CSV-based dataset** of real and fake audio samples.
- **Streamlit** for a lightweight, web-based UI to upload `.wav` files and view predictions instantly.

---

## ğŸ› ï¸ Tech Stack

- **Python 3.9+**
- **Scikit-learn** (for Random Forest Model)
- **Streamlit** (for web application UI)
- **Librosa** (for audio feature extraction)
- **Pandas** & **NumPy** (for data handling)

---

## ğŸš€ Features

- Upload an audio `.wav` file and get instant prediction (Real / Fake).
- Audio feature extraction on the fly.
- Fast inference using a pre-trained Random Forest model.
- Clean and user-friendly Streamlit interface.

---

## ğŸ“‚ Project Structure

```
DEEPFAKE DETECTION/
â”‚
â”œâ”€â”€ .venv/                          # Virtual environment (ignored by Git)
â”‚
â”œâ”€â”€ AudioSamples/                   # Test audio samples
â”‚   â”œâ”€â”€ FAKE/                        # Folder containing fake audio samples (.wav)
â”‚   â””â”€â”€ REAL/                        # Folder containing real audio samples (.wav)
â”‚
â”œâ”€â”€ .gitignore                      # Git ignore file
â”œâ”€â”€ app_1.py                        # Main Streamlit app (UI for uploading and prediction)
â”œâ”€â”€ newTrain_1.py                   # Script for training RandomForest model
â”‚
â”œâ”€â”€ audio_deepfake_model.pkl        # Trained RandomForest model (saved after training)
â”œâ”€â”€ feature_scaler.pkl              # Scaler used for feature normalization during training
â”œâ”€â”€ scaler.pkl                      # (Seems duplicate - can merge with feature_scaler.pkl if same)
â”‚
â”œâ”€â”€ confusion_matrix.png            # Visualization of model performance (confusion matrix)
â”œâ”€â”€ DATASET-balanced.csv            # Feature dataset (extracted features + labels)
â”‚
â”œâ”€â”€ requirements.txt                # List of required Python packages
â””â”€â”€ README.md                       # Project documentation (you'll add this)

```

---

## ğŸ“ˆ How It Works

1. **Feature Extraction**:  
   When an audio file is uploaded, features like MFCCs, Chroma, Spectral Centroid, etc., are extracted using `librosa`.
   
2. **Model Prediction**:  
   The extracted feature vector is passed to a **Random Forest Classifier** trained previously on a labeled dataset.

3. **Result Display**:  
   The app immediately displays whether the audio is **REAL** or **FAKE** based on the model's prediction.

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/RohanBage/Audio-DeepFake-Detection.git
cd Audio-DeepFake-Detection
```

### 2. Create and Activate a Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate    # On macOS/Linux
venv\Scripts\activate       # On Windows
```

### 3. Install Required Packages

```bash
pip install -r requirements.txt
```

### 4. Run the Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ“Š Example

> Upload a `.wav` file in the app.  
> You will get an output like:

âœ… **Prediction: Real Audio**

or

âŒ **Prediction: Fake Audio**

---

## ğŸ¤” Future Work

- Improve model accuracy using deep learning models (e.g., CNNs or RNNs).
- Handle additional audio formats (e.g., MP3, FLAC).
- Provide probability/confidence scores with predictions.
- Train with larger and more diverse datasets (e.g., SceneFake, FoR datasets).

---


## ğŸ“¬ Contact

Made with â¤ï¸ by [Rohan Bage](https://github.com/RohanBage)

